# LLM Inference C++ Wrapper

Production-ready C++ wrapper for local LLM inference.

## Features
- Sub-100ms first token latency
- Streaming & batch generation
- Configurable threading

## Build
```bash
mkdir build && cd build
cmake ..
make
./demo